{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tools.segmentation.stats import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mrcnn import visualize\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from dicom_to_cnn.tools.cleaning_dicom.folders import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_pred_path = '/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/prediction_dataset_probs.csv'\n",
    "df = pd.read_csv(csv_pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = []\n",
    "number = []\n",
    "for idx,name in enumerate(df['study'].value_counts().index.tolist()):\n",
    "    #print('Study:', name)\n",
    "    study.append(name)\n",
    "    #print('Number :', df['study'].value_counts()[idx])\n",
    "    number.append(df['study'].value_counts()[idx])\n",
    "print(study)\n",
    "print(number)\n",
    "\n",
    "percent = []\n",
    "for s, n in zip(study, number):\n",
    "    print(s)\n",
    "    print(\"{} % \".format(round(n/np.sum(number)*100,2)))\n",
    "    print('')\n",
    "    percent.append(round(n/np.sum(number)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values.tolist()\n",
    "print(\"NUMBER OF INFERENCE : \", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#GLOBAL DICE WITHOUT THRESHOLD \n",
    "for inference in dataset : \n",
    "    print(inference[6])\n",
    "    print(dataset.index(inference)) \n",
    "    pred_array, _ = get_array_from_nifti(inference[6])\n",
    "    true_array, _ = get_array_from_nifti(inference[5])\n",
    "    pet_array, spacing = get_array_from_nifti(inference[4])\n",
    "    true_array = multi_seuil_mask(true_array, pet_array)\n",
    "    dice = calcul_dice_global(pred_array, true_array)\n",
    "    print(dice)\n",
    "    inference.append(dice[0])\n",
    "    filename = inference[1]\n",
    "    write_json_file('/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/dice_v2', filename, inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory ='/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/dice_v2'\n",
    "liste_json = os.listdir(directory)\n",
    "full_liste = []\n",
    "for json_file in liste_json : \n",
    "    full_liste.append(os.path.join(directory, json_file))\n",
    "\n",
    "print(len(full_liste)) #must be 369\n",
    "dataset = []\n",
    "for json_file in full_liste : \n",
    "    with open(json_file) as json_file : \n",
    "        reader = json.load(json_file)\n",
    "        dataset.append(reader)\n",
    "print(dataset[0])\n",
    "filename = 'inference_dice_dataset_v2.csv'\n",
    "\n",
    "with open(os.path.join(directory, filename), 'w') as csv_file : \n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow([\"patient_id\", \"study_uid\", \"study\", \"ct_img\", \"pet_img\", \"mask_img\", \"pred_img\", \"dice\"])\n",
    "    for serie in dataset: \n",
    "        csv_writer.writerow([serie[0], serie[1], serie[2], serie[3], serie[4], serie[5], serie[6], serie[7]])"
   ]
  },
  {
   "source": [
    "#DICE \n",
    "seuil = [0.41, 2.5, 4.0]\n",
    "for inference in dataset:\n",
    "    print(inference[6])\n",
    "    print(dataset.index(inference)) \n",
    "    pet_array, spacing = get_array_from_nifti(inference[4])\n",
    "    array = sitk.GetArrayFromImage(sitk.ReadImage(inference[-1]))\n",
    "    if int(np.max(array)) != 1 : #pas de segmentation faite avec le model \n",
    "        inference.append(0)\n",
    "        inference.append(0)\n",
    "        inference.append(0)\n",
    "        filename = inference[1]+'_'+str(s)\n",
    "        write_json_file('/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/dice_v2', filename, inference)\n",
    "    else : \n",
    "        for s in seuil : \n",
    "            if s == 0.41 : \n",
    "                ws_img = applied_watershed_on_inference(inference[6], inference[4])\n",
    "                pred_array = sitk.GetArrayFromImage(ws_img)\n",
    "                true_array, _ = get_array_from_nifti(inference[5]) \n",
    "                dice = calcul_dice_threshold(pred_array, true_array, pet_array, thresh = s)\n",
    "                inference.append(dice[0])\n",
    "                filename = inference[1]+'_'+str(s)\n",
    "                write_json_file('/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/dice_v2', filename, inference)\n",
    "                print(dice)\n",
    "                \n",
    "            else : \n",
    "                \n",
    "                pred_array, _ = get_array_from_nifti(inference[6])\n",
    "                true_array, _ = get_array_from_nifti(inference[5])\n",
    "                dice = calcul_dice_threshold(pred_array, true_array, pet_array, thresh = s)\n",
    "                inference.append(dice[0])\n",
    "                filename = inference[1]+'_'+str(s)\n",
    "                write_json_file('/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/dice_v2', filename, inference)\n",
    "                print(dice)\n",
    "            "
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_dice \n",
    "\n",
    "directory ='/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/dice'\n",
    "liste_json = os.listdir(directory)\n",
    "full_liste = []\n",
    "for json_file in liste_json : \n",
    "    if '_4.0' in json_file : \n",
    "        full_liste.append(os.path.join(directory, json_file))\n",
    "\n",
    "print(len(full_liste)) #must be 369\n",
    "dataset = []\n",
    "for json_file in full_liste : \n",
    "    with open(json_file) as json_file : \n",
    "        reader = json.load(json_file)\n",
    "        dataset.append(reader)\n",
    "print(dataset[0])\n",
    "filename = 'inference_dice_dataset.csv'\n",
    "\n",
    "with open(os.path.join(directory, filename), 'w') as csv_file : \n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow([\"patient_id\", \"study_uid\", \"study\", \"ct_img\", \"pet_img\", \"mask_img\", \"pred_img\", \"dice_0.41\", \"dice_2.5\", \"dice_4.0\"])\n",
    "    for serie in dataset: \n",
    "        csv_writer.writerow([serie[0], serie[1], serie[2], serie[3], serie[4], serie[5], serie[6], serie[7], serie[8], serie[9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#TMTV\n",
    "seuil = [0.41, 2.5, 4.0]\n",
    "for inference in dataset : \n",
    "    print(dataset.index(inference))\n",
    "    pet_array, spacing = get_array_from_nifti(inference[4])\n",
    "    for s in seuil : \n",
    "        if s == 0.41 : \n",
    "            #Watershed\n",
    "            ws_img = applied_watershed_on_inference(inference[6], inference[4])\n",
    "            pred_array = sitk.GetArrayFromImage(ws_img)\n",
    "            true_array, _ = get_array_from_nifti(inference[5]) \n",
    "            tmtv_pred, tmtv_true = calcul_tmtv(pred_array, true_array, pet_array, spacing, thresh = s)\n",
    "            inference.append(tmtv_pred)\n",
    "            inference.append(tmtv_true)\n",
    "            filename = inference[1]+'_'+str(s)\n",
    "            write_json_file('/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/tmtv', filename, inference)\n",
    "            #print(\"tmtv_pred :\", tmtv_pred)\n",
    "            #print(\"tmtv_true :\", tmtv_true)\n",
    "            \n",
    "        else : \n",
    "            \n",
    "            pred_array, _ = get_array_from_nifti(inference[6])\n",
    "            true_array, _ = get_array_from_nifti(inference[5])\n",
    "            tmtv_pred, tmtv_true = calcul_tmtv(pred_array, true_array, pet_array, spacing, thresh = s)\n",
    "            inference.append(tmtv_pred)\n",
    "            inference.append(tmtv_true)\n",
    "            filename = inference[1]+'_'+str(s)\n",
    "            write_json_file('/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/tmtv', filename, inference)\n",
    "            #print(\"tmtv_pred :\", tmtv_pred)\n",
    "            #print(\"tmtv_true :\", tmtv_true)\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_tmtv\n",
    "\n",
    "directory = '/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/tmtv'\n",
    "liste_json = os.listdir(directory)\n",
    "full_liste = []\n",
    "for json_file in liste_json : \n",
    "    if '_4.0' in json_file : \n",
    "        full_liste.append(os.path.join(directory, json_file))\n",
    "\n",
    "print(len(full_liste)) #must be 369\n",
    "dataset = []\n",
    "for json_file in full_liste : \n",
    "    with open(json_file) as json_file : \n",
    "        reader = json.load(json_file)\n",
    "        dataset.append(reader)\n",
    "filename = 'inference_tmtv_dataset.csv'\n",
    "\n",
    "with open(os.path.join(directory, filename), 'w') as csv_file : \n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow([\"patient_id\", \"study_uid\", \"study\", \"ct_img\", \"pet_img\", \"mask_img\", \"pred_img\", \"pred_0.41\", \"true_0.41\", \"pred_2.5\", \"true_2.5\", \"pred_4.0\", \"true_4.0\"])\n",
    "    for serie in dataset: \n",
    "        csv_writer.writerow([serie[0], serie[1], serie[2], serie[3], serie[4], serie[5], serie[6], serie[7], serie[8], serie[9], serie[10], serie[11], serie[12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STATS ON GLOBAL DICE \n",
    "#STATS ON DICE THRESHOLD\n",
    "import numpy as np\n",
    "csv_path= '/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/dice_v2/inference_dice_dataset_v2.csv'\n",
    "with open(csv_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ',') #liste pour chaque ligne \n",
    "    dataset = []\n",
    "    for row in reader :\n",
    "        dataset.append(row)\n",
    "        \n",
    "del dataset[0] #enlever première ligne\n",
    "\n",
    "dice = []\n",
    "for row in dataset : \n",
    "    dice.append(float(row[-1]))\n",
    "\n",
    "print('stats on segmentation : ')\n",
    "print(\"dice max : \", np.max(dice))\n",
    "print(\"dice min :\", np.min(dice))\n",
    "print('dice mean :', np.mean(dice))\n",
    "print('dice median :' , np.median(dice))\n",
    "print('dice std :', np.std(dice))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STATS ON DICE THRESHOLD\n",
    "csv_path= '/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/dice/inference_dice_dataset.csv'\n",
    "with open(csv_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ',') #liste pour chaque ligne \n",
    "    dataset = []\n",
    "    for row in reader :\n",
    "        dataset.append(row)\n",
    "        \n",
    "del dataset[0] #enlever première ligne\n",
    "\n",
    "dice_0_41 = []\n",
    "dice_2_5 = []\n",
    "dice_4_0 = []\n",
    "small_dice = []\n",
    "for row in dataset : \n",
    "    #if row[-3] <= '0.4' or row[-2] <= '0.4' or row[-1] <= '0.4' : \n",
    "     #   small_dice.append(row)\n",
    "    #else : \n",
    "    dice_0_41.append(float(row[-3]))\n",
    "    dice_2_5.append(float(row[-2]))\n",
    "    dice_4_0.append(float(row[-1]))\n",
    "print(len(dice_0_41))\n",
    "print(len(dice_2_5))\n",
    "print(len(dice_4_0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#287/369 qui ont un dice plus grand que 0.5 sur une des trois segmentation\n",
    "#21/369 qui ont un dice plus grand que 0.3 sur une des trois segmentation\n",
    "#336/369 qui ont un dice plus grand que 0.3 sur une des trois segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('stats on 0.41 segmentation : ')\n",
    "print(\"dice max : \", np.max(dice_0_41))\n",
    "print(\"dice min :\", np.min(dice_0_41))\n",
    "print('dice mean :', np.mean(dice_0_41))\n",
    "print('dice median :' , np.median(dice_0_41))\n",
    "print('dice std :', np.std(dice_0_41))\n",
    "print('')\n",
    "print('')\n",
    "print('stats on 2.5 segmentation : ')\n",
    "print(\"dice max : \", np.max(dice_2_5))\n",
    "print(\"dice min :\", np.min(dice_2_5))\n",
    "print('dice mean :', np.mean(dice_2_5))\n",
    "print('dice median :' , np.median(dice_2_5))\n",
    "print('dice std :', np.std(dice_2_5))\n",
    "print('')\n",
    "print('')\n",
    "print('stats on 4.0 segmentation : ')\n",
    "print(\"dice max : \", np.max(dice_4_0))\n",
    "print(\"dice min :\", np.min(dice_4_0))\n",
    "print('dice mean :', np.mean(dice_4_0))\n",
    "print('dice median :' , np.median(dice_4_0))\n",
    "print('dice std :', np.std(dice_4_0))\n",
    "\n",
    "\n",
    "#dice moyen : \n",
    "print('')\n",
    "print('')\n",
    "print('mean dice on every segmentation :', (np.mean(dice_0_41)+np.mean(dice_2_5)+np.mean(dice_4_0)) / 3)\n",
    "print('mean of median dice on every segmentation :', (np.median(dice_0_41)+ np.median(dice_2_5)+np.median(dice_4_0)) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STATS ON TMTV \n",
    "csv_path= '/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/tmtv/inference_tmtv_dataset.csv'\n",
    "with open(csv_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ',') #liste pour chaque ligne \n",
    "    dataset = []\n",
    "    for row in reader :\n",
    "        dataset.append(row)\n",
    "        \n",
    "del dataset[0] #enlever première ligne\n",
    "\n",
    "\n",
    "tmtv_0_41_pred = []\n",
    "tmtv_2_5_pred = []\n",
    "tmtv_4_0_pred = []\n",
    "tmtv_0_41_true = []\n",
    "tmtv_2_5_true = []\n",
    "tmtv_4_0_true = []\n",
    "\n",
    "for row in dataset : \n",
    "    tmtv_0_41_pred.append(float(row[-6]))#pred 0.41\n",
    "    tmtv_0_41_true.append(float(row[-5]))#true 0.41\n",
    "    tmtv_2_5_pred.append(float(row[-4]))#pred 2.5\n",
    "    tmtv_2_5_true.append(float(row[-3]))#true 2.5\n",
    "    tmtv_4_0_pred.append(float(row[-2])) #pred 4.0\n",
    "    tmtv_4_0_true.append(float(row[-1]))#true 4.0\n",
    "\n",
    "print(len(tmtv_0_41_pred))\n",
    "print(len(tmtv_0_41_true))\n",
    "print(len(tmtv_2_5_pred))\n",
    "print(len(tmtv_2_5_true))\n",
    "print(len(tmtv_4_0_pred))\n",
    "print(len(tmtv_4_0_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('stats on tmtv 0.41 : ')\n",
    "stats_0_41 = []\n",
    "maxi = calcul_max_tmtv(tmtv_0_41_pred, tmtv_0_41_true)\n",
    "mini = calcul_min_tmtv(tmtv_0_41_pred, tmtv_0_41_true)\n",
    "mean_ = calcul_mean_on_tmtv(tmtv_0_41_pred, tmtv_0_41_true)\n",
    "median_ = calcul_median_on_tmtv(tmtv_0_41_pred, tmtv_0_41_true)\n",
    "sd = calcul_sd_tmtv(tmtv_0_41_pred, tmtv_0_41_true)\n",
    "q1 = calcul_q1_tmtv(tmtv_0_41_pred, tmtv_0_41_true)\n",
    "q3 =  calcul_q3_tmtv(tmtv_0_41_pred, tmtv_0_41_true)\n",
    "stats_0_41.append(maxi)\n",
    "stats_0_41.append(mini)\n",
    "stats_0_41.append(mean_)\n",
    "stats_0_41.append(median_)\n",
    "stats_0_41.append(sd)\n",
    "stats_0_41.append(q1)\n",
    "stats_0_41.append(q3)\n",
    "print('max :', maxi)\n",
    "print('min :', mini)\n",
    "print('mean :', mean_)\n",
    "print('median :', median_)\n",
    "print('sd :', sd)\n",
    "print('q1 : ', q1)\n",
    "print('q3 :', q3)\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "print('stats on tmtv 2.5 : ')\n",
    "stats_2_5 = []\n",
    "maxi = calcul_max_tmtv(tmtv_2_5_pred, tmtv_2_5_true)\n",
    "mini = calcul_min_tmtv(tmtv_2_5_pred, tmtv_2_5_true)\n",
    "mean_ = calcul_mean_on_tmtv(tmtv_2_5_pred, tmtv_2_5_true)\n",
    "median_ = calcul_median_on_tmtv(tmtv_2_5_pred, tmtv_2_5_true)\n",
    "sd = calcul_sd_tmtv(tmtv_2_5_pred, tmtv_2_5_true)\n",
    "q1 = calcul_q1_tmtv(tmtv_2_5_pred, tmtv_2_5_true)\n",
    "q3 =  calcul_q3_tmtv(tmtv_2_5_pred, tmtv_2_5_true)\n",
    "stats_2_5.append(maxi)\n",
    "stats_2_5.append(mini)\n",
    "stats_2_5.append(mean_)\n",
    "stats_2_5.append(median_)\n",
    "stats_2_5.append(sd)\n",
    "stats_2_5.append(q1)\n",
    "stats_2_5.append(q3)\n",
    "print('max :', maxi)\n",
    "print('min :', mini)\n",
    "print('mean :', mean_)\n",
    "print('median :', median_)\n",
    "print('sd :', sd)\n",
    "print('q1 : ', q1)\n",
    "print('q3 :', q3)\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "print('stats on tmtv 4.0 : ')\n",
    "stats_4_0 = []\n",
    "maxi = calcul_max_tmtv(tmtv_4_0_pred, tmtv_4_0_true)\n",
    "mini = calcul_min_tmtv(tmtv_4_0_pred, tmtv_4_0_true)\n",
    "mean_ = calcul_mean_on_tmtv(tmtv_4_0_pred, tmtv_4_0_true)\n",
    "median_ = calcul_median_on_tmtv(tmtv_4_0_pred, tmtv_4_0_true)\n",
    "sd = calcul_sd_tmtv(tmtv_4_0_pred, tmtv_4_0_true)\n",
    "q1 = calcul_q1_tmtv(tmtv_4_0_pred, tmtv_4_0_true)\n",
    "q3 =  calcul_q3_tmtv(tmtv_4_0_pred, tmtv_4_0_true)\n",
    "stats_4_0.append(maxi)\n",
    "stats_4_0.append(mini)\n",
    "stats_4_0.append(mean_)\n",
    "stats_4_0.append(median_)\n",
    "stats_4_0.append(sd)\n",
    "stats_4_0.append(q1)\n",
    "stats_4_0.append(q3)\n",
    "print('max :', maxi)\n",
    "print('min :', mini)\n",
    "print('mean :', mean_)\n",
    "print('median :', median_)\n",
    "print('sd :', sd)\n",
    "print('q1 : ', q1)\n",
    "print('q3 :', q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOXPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "type_ = []\n",
    "for i in range(369):\n",
    "    type_.append('prediction')\n",
    "for i in range(369):\n",
    "    type_.append('manual')\n",
    "print(len(type_))\n",
    "\n",
    "df = pd.DataFrame([tmtv_0_41_pred+ tmtv_0_41_true, type_]).transpose()\n",
    "df.columns = ['TMTV (ml)', 'type']\n",
    "df\n",
    "fig, ax = plt.subplots()\n",
    "# the size of A4 paper\n",
    "fig.set_size_inches(10,10)\n",
    "ax = sns.boxplot(x=\"type\", y=\"TMTV (ml)\", hue=\"type\",\n",
    "                 data=df, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_ = []\n",
    "for i in range(369):\n",
    "    type_.append('prediction')\n",
    "for i in range(369):\n",
    "    type_.append('manual')\n",
    "print(len(type_))\n",
    "\n",
    "df = pd.DataFrame([tmtv_2_5_pred+ tmtv_2_5_true, type_]).transpose()\n",
    "df.columns = ['TMTV (ml)', 'type']\n",
    "df\n",
    "fig, ax = plt.subplots()\n",
    "# the size of A4 paper\n",
    "fig.set_size_inches(10,10)\n",
    "ax = sns.boxplot(x=\"type\", y=\"TMTV (ml)\", hue=\"type\",\n",
    "                 data=df, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_ = []\n",
    "for i in range(369):\n",
    "    type_.append('prediction')\n",
    "for i in range(369):\n",
    "    type_.append('manual')\n",
    "print(len(type_))\n",
    "\n",
    "df = pd.DataFrame([tmtv_4_0_pred+ tmtv_4_0_true, type_]).transpose()\n",
    "df.columns = ['TMTV (ml)', 'type']\n",
    "df\n",
    "fig, ax = plt.subplots()\n",
    "# the size of A4 paper\n",
    "fig.set_size_inches(10,10)\n",
    "ax = sns.boxplot(x=\"type\", y='TMTV (ml)', hue=\"type\",\n",
    "                 data=df, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation \n",
    "#0.41 \n",
    "import scipy.stats as ss \n",
    "\n",
    "\n",
    "correlation = ss.spearmanr(tmtv_0_41_true, tmtv_0_41_pred)\n",
    "print(correlation)\n",
    "line = []\n",
    "for x in tmtv_0_41_true : \n",
    "    line.append(x*correlation[0] + correlation[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.scatter(tmtv_0_41_true, tmtv_0_41_pred)\n",
    "plt.plot(tmtv_0_41_true, line, linewidth = 2, color='red', label='R =  {}'.format(correlation[0]))\n",
    "plt.plot([0,3700], [0,3700], label='x=y', linestyle='--')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('manual TMTV (ml')\n",
    "plt.ylabel('predicted TMTV (ml)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5 \n",
    "correlation = ss.spearmanr(tmtv_2_5_true, tmtv_2_5_pred)\n",
    "print(correlation)\n",
    "line = []\n",
    "for x in tmtv_2_5_true : \n",
    "    line.append(x*correlation[0] + correlation[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.scatter(tmtv_2_5_true, tmtv_2_5_pred)\n",
    "plt.plot(tmtv_2_5_true, line, linewidth = 2, color='red', label='R =  {}'.format(correlation[0]))\n",
    "plt.plot([0,3900], [0,3900], label='x=y', linestyle='--')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('manual TMTV (ml')\n",
    "plt.ylabel('predicted TMTV (ml)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = ss.spearmanr(tmtv_4_0_true, tmtv_4_0_pred)\n",
    "print(correlation)\n",
    "line = []\n",
    "for x in tmtv_4_0_true : \n",
    "    line.append(x*correlation[0] + correlation[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.scatter(tmtv_4_0_true, tmtv_4_0_pred)\n",
    "plt.plot(tmtv_4_0_true, line, linewidth = 2, color='red', label='R =  {}'.format(correlation[0]))\n",
    "plt.plot([0,3200], [0,3200], label='x=y', linestyle='--')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('manual TMTV (ml')\n",
    "plt.ylabel('predicted TMTV (ml)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLAND ALTMAN \n",
    "#0.41 \n",
    "\n",
    "mean = []\n",
    "diff = []\n",
    "for i in range(len(tmtv_0_41_true)):\n",
    "    subliste = []\n",
    "    subliste.append(tmtv_0_41_true[i])\n",
    "    subliste.append(tmtv_0_41_pred[i])\n",
    "    mean.append(np.mean(subliste))\n",
    "\n",
    "    diff.append(tmtv_0_41_true[i] - tmtv_0_41_pred[i])\n",
    "f = plt.figure(figsize=(15,10))\n",
    "axes = plt.gca()\n",
    "moy= np.mean(diff)\n",
    "sd = np.std(diff)\n",
    "plt.axhline(moy, c='r', label='mean', linewidth=3)\n",
    "plt.axhline(moy + 2*sd, c='green', label = 'm + 2sd' )\n",
    "plt.axhline(moy - 2*sd, c='green', label = 'm - 2sd' )\n",
    "plt.legend()\n",
    "plt.xlabel('mean(tmtv_pred, tmtv_manual) (ml)', fontsize = 16)\n",
    "plt.ylabel('diff(tmtv_pred, tmtv_manual) (ml) ', fontsize = 16)\n",
    "plt.scatter(mean, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5\n",
    "mean = []\n",
    "diff = []\n",
    "for i in range(len(tmtv_2_5_true)):\n",
    "    subliste = []\n",
    "    subliste.append(tmtv_2_5_true[i])\n",
    "    subliste.append(tmtv_2_5_pred[i])\n",
    "    mean.append(np.mean(subliste))\n",
    "\n",
    "    diff.append(tmtv_2_5_true[i] - tmtv_2_5_pred[i])\n",
    "\n",
    "f = plt.figure(figsize=(15,10))\n",
    "axes = plt.gca()\n",
    "moy= np.mean(diff)\n",
    "sd = np.std(diff)\n",
    "plt.axhline(moy, c='r', label='mean', linewidth=3)\n",
    "plt.axhline(moy + 2*sd, c='green', label = 'm + 2sd' )\n",
    "plt.axhline(moy - 2*sd, c='green', label = 'm - 2sd' )\n",
    "plt.scatter(mean, diff)\n",
    "plt.xlabel('mean(tmtv_pred, tmtv_manual) (ml)', fontsize = 16)\n",
    "plt.ylabel('diff(tmtv_pred, tmtv_manual) (ml) ', fontsize = 16)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.0\n",
    "mean = []\n",
    "diff = []\n",
    "for i in range(len(tmtv_4_0_true)):\n",
    "    subliste = []\n",
    "    subliste.append(tmtv_4_0_true[i])\n",
    "    subliste.append(tmtv_4_0_pred[i])\n",
    "    mean.append(np.mean(subliste))\n",
    "\n",
    "    diff.append(tmtv_4_0_true[i] - tmtv_4_0_pred[i])\n",
    "\n",
    "f = plt.figure(figsize=(15,10))\n",
    "axes = plt.gca()\n",
    "moy= np.mean(diff)\n",
    "sd = np.std(diff)\n",
    "plt.axhline(moy, c='r', label='mean', linewidth=3)\n",
    "plt.axhline(moy + 2*sd, c='green', label = 'm + 2sd' )\n",
    "plt.axhline(moy - 2*sd, c='green', label = 'm - 2sd' )\n",
    "plt.scatter(mean, diff)\n",
    "plt.xlabel('mean(tmtv_pred, tmtv_manual) (ml)', fontsize = 16)\n",
    "plt.ylabel('diff(tmtv_pred, tmtv_manual) (ml) ', fontsize = 16)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concardance kappa AHL \n",
    "csv_path= csv_path= '/media/oncopole/d508267f-cc7d-45e2-ae24-9456e005a01f/SEGMENTATION/training/20210621-14:00:08/inference/stats/tmtv/inference_tmtv_dataset.csv'\n",
    "with open(csv_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ',') #liste pour chaque ligne \n",
    "    dataset = []\n",
    "    for row in reader :\n",
    "        dataset.append(row)\n",
    "        \n",
    "del dataset[0] #enlever première ligne\n",
    "\n",
    "ahl_true = []\n",
    "ahl_pred = []\n",
    "for row in dataset : \n",
    "    if 'ahl' in row : \n",
    "        ahl_pred.append(float(row[-2]))\n",
    "        ahl_true.append(float(row[-1]))\n",
    "print(len(ahl_pred))\n",
    "print(len(ahl_true))\n",
    "\n",
    "\n",
    "binary_true = []\n",
    "binary_pred = []\n",
    "\n",
    "for true in ahl_true : \n",
    "    if true < 220 : \n",
    "        binary_true.append(0)\n",
    "    else : binary_true.append(1)\n",
    "\n",
    "for pred in ahl_pred : \n",
    "    if pred < 220 : \n",
    "        binary_pred.append(0)\n",
    "    else : binary_pred.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score \n",
    "\n",
    "score = cohen_kappa_score(binary_true, binary_pred)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}