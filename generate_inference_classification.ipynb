{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from classification.pre_process.Prep_CSV import Prep_CSV\n",
    "from classification.pre_process.Preprocessing import Preprocessing \n",
    "from utils.predict_process import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = ''\n",
    "model = tf.keras.models.load_model(trained_model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/result.json'\n",
    "csv_dataset_path = ''\n",
    "\n",
    "preprocessing_objet = Preprocessing(objet.csv_path)\n",
    "X, y = preprocessing_objet.normalize_encoding_dataset()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42, test_size = 0.15) #random state \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state = 42, test_size = 0.15)\n",
    "#same random state as in training\n",
    "\n",
    "print(\"size of X_train : \", X_train.shape)\n",
    "print(\"size of y_train : \",y_train.shape)\n",
    "print(\"\")\n",
    "print(\"size of X_test : \", X_test.shape)\n",
    "print(\"size of y_test : \",y_test.shape)\n",
    "print(\"\")\n",
    "print(\"size of X_val : \", X_val.shape)\n",
    "print(\"size of y_val : \",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate\n",
    "result = model.evaluate(X_test,  {'head': y_test[:,0], \n",
    "                                    'leg': y_test[:,1],\n",
    "                                    'right_arm' : y_test[:,2],\n",
    "                                    'left_arm' : y_test[:,3] ,\n",
    "                                    })\n",
    "dict(zip(model.metrics_names, result)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "inferences = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}