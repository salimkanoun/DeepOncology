{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from classification.tools.prepare_csv_from_json import *\n",
    "from classification.pre_process.Preprocessing import Preprocessing \n",
    "from utils.predict_process import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = ''\n",
    "model = tf.keras.models.load_model(trained_model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_path = ''\n",
    "#csv path has [study_id, path_image_png, upper_limit, lower_limit, right_arm, left_arm]per row\n",
    "preprocessing_objet = Preprocessing(csv_path)\n",
    "X, y = preprocessing_objet.normalize_encoding_dataset()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42, test_size = 0.15) #random state \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state = 42, test_size = 0.15)\n",
    "#same random state as in training\n",
    "\n",
    "print(\"size of X_train : \", X_train.shape)\n",
    "print(\"size of y_train : \",y_train.shape)\n",
    "print(\"\")\n",
    "print(\"size of X_test : \", X_test.shape)\n",
    "print(\"size of y_test : \",y_test.shape)\n",
    "print(\"\")\n",
    "print(\"size of X_val : \", X_val.shape)\n",
    "print(\"size of y_val : \",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate\n",
    "result = model.evaluate(X_test,  {'head': y_test[:,0], \n",
    "                                    'leg': y_test[:,1],\n",
    "                                    'right_arm' : y_test[:,2],\n",
    "                                    'left_arm' : y_test[:,3] ,\n",
    "                                    })\n",
    "dict(zip(model.metrics_names, result)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "inferences = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferences_decoded = decodage_predictions(inferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_decoded = decodage_truth(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate image with true/false predictions and save them \n",
    "directory = ''\n",
    "affichage(X_test, inferences_decoded, truth_decoded, directory)"
   ]
  }
 ]
}